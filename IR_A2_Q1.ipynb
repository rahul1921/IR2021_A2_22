{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IR_A2_Q1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aRNAJxcZ2pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddb050b-73b2-4fbd-b626-451399de1785"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.stem.porter import PorterStemmer\n",
        "!pip install autocorrect\n",
        "from autocorrect import Speller\n",
        "from collections import OrderedDict \n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import spacy \n",
        "import re\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "!pip install contractions\n",
        "!pip install spacy\n",
        "!pip install textblob\n",
        "import contractions\n",
        "from textblob import TextBlob, Word\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: autocorrect in /usr/local/lib/python3.7/dist-packages (2.4.0)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.48)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (54.2.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKRlGOH7RPU6"
      },
      "source": [
        "paths = []\n",
        "filename = []\n",
        "# /content/drive/MyDrive/stories\n",
        "# /content/drive/MyDrive/IR ASSIGNMENT 2/stories\n",
        "for (dirpath, dirnames, filenames) in os.walk(\"/content/drive/MyDrive/stories\"):\n",
        "  for i in filenames:\n",
        "    paths.append(str(dirpath)+str(\"/\")+i)\n",
        "    filename.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7BoFg0tdp1f",
        "outputId": "11d6d7c1-a933-4e11-be91-07eff9579f0d"
      },
      "source": [
        "len(paths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nRuDxXrbv1V"
      },
      "source": [
        "documentsDict = {}\n",
        "# filenameOfDoc = {}\n",
        "# global counter \n",
        "# counter = 0\n",
        "def cleaning(filepath,filename,flag):\n",
        "  if(flag==1):\n",
        "    f = open(filepath, 'r', errors = 'ignore',encoding='cp1250').read().strip()\n",
        "    clean_S = contractions.fix(f)\n",
        "    clean_S=re.sub(\"([\\-]{1,2})\", \" \",clean_S)\n",
        "    clean_s=re.sub(\"[\\,]\", \" \",clean_S)\n",
        "    clean_S = re.sub(\"[\\.]\",\" \",clean_S)\n",
        "    clean_S = re.sub(r'[\\!@#$%^&\\*()\\_+={}\\:\\;<>\\?/\\|\\-/\"\\']*',\"\", clean_S)  #junk symbols\n",
        "    # clean_S = re.sub(r\"(.)\\1{2}\",\"\",clean_S)  #for elongated words\n",
        "    clean_S=re.sub(\"([\\.\\!]{2})\", \" \",clean_S)  #removing punctuations\n",
        "    clean_S = re.sub('\\s+', ' ', clean_S)    \n",
        "    clean_S=re.sub(\"[^a-zA-Z\\s\\n]\", \" \",clean_S)  #used to eliminate non-ascii and numeric symbols \n",
        "    clean_S = re.sub(r\"(.)\\1{2}\",\"\",clean_S)  #for elongated words\n",
        "    clean_S = clean_S.lower()\n",
        "    documentsDict[filename]=clean_S\n",
        "    # counter = counter+1\n",
        "    # filenameOfDoc[counter] = filename\n",
        "\n",
        "  elif(flag==0):\n",
        "    filepath = contractions.fix(filepath)\n",
        "    filepath=re.sub(\"([\\-]{1,2})\", \" \",filepath)\n",
        "    filepath=re.sub(\"[0-9]\", \"\",filepath)\n",
        "    # filepath=re.sub(\"[\\,]\", \" \",filepath)\n",
        "    filepath = re.sub(r'[\\!@#$%^&\\*()\\_+={}\\:\\;<>\\?/\\|\\-/\"\\']*',\"\", filepath)\n",
        "    # filepath = re.sub(r\"(.)\\1{2}\",\"\",filepath)  #for elongated words\n",
        "    filepath=re.sub(\"([\\.\\!]{2})\", \" \",filepath)\n",
        "    filepath = re.sub('\\s+', ' ', filepath)\n",
        "    filepath=re.sub(\"[^a-zA-Z\\s\\n]\", \" \",filepath)\n",
        "    filepath = re.sub(r\"(.)\\1{2}\",\"\",filepath)  #for elongated words\n",
        "    filepath = filepath.lower()\n",
        "    return filepath"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAp1G6CYh0wl"
      },
      "source": [
        "for i in range(0,len(filename)):\n",
        "       cleaning(paths[i],filename[i],1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieB0zeUUjHnd",
        "outputId": "0b4f4436-c8c3-435c-8046-f6605642e24f"
      },
      "source": [
        "len(documentsDict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdTF937L_8EM"
      },
      "source": [
        "f = open('cleaneddidSomeChange.txt', 'w')\n",
        "f.write(str(documentsDict))\n",
        "f.close()"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf7aFYpWhAKD"
      },
      "source": [
        "f = open('cleaneddidSomeChange.txt', 'r')\n",
        "documentsDict = f.read()\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj0s-O-xlIVB"
      },
      "source": [
        "def gen_token(flag,query):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  if(flag==1):\n",
        "    for docname in documentsDict:\n",
        "        documentsDict[docname] = tokenizer.tokenize(str(documentsDict[docname]))\n",
        "\n",
        "  elif(flag==0):\n",
        "    query = tokenizer.tokenize(query)\n",
        "    return query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOLTF5vAolhE"
      },
      "source": [
        "def remove_stopword(flag,query):\n",
        "  stopwordsList = stopwords.words('english')\n",
        "  if(flag==1):\n",
        "    for docname in documentsDict:\n",
        "        for word in documentsDict[docname]:\n",
        "            if word in stopwordsList:\n",
        "                documentsDict[docname].remove(word)\n",
        "  elif(flag==0):\n",
        "      q=[]\n",
        "      for word in query:\n",
        "            if word not in stopwordsList:\n",
        "              q.append(word)\n",
        "      query=q.copy()\n",
        "      return query"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIB_eUyhopoS"
      },
      "source": [
        "def normalise_using_textblob(flag,query):\n",
        "  if(flag==1):       \n",
        "    for docname in documentsDict:\n",
        "        dataList = []\n",
        "        for word in documentsDict[docname]:\n",
        "            w = Word(word)\n",
        "            dataList.append(w.lemmatize())\n",
        "        documentsDict[docname] = dataList   \n",
        "  elif(flag==0):\n",
        "    ans = []\n",
        "    for word in query:\n",
        "      w=Word(word)\n",
        "      ans.append(w.lemmatize())\n",
        "    return ans"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mprgn3UsY6Ub"
      },
      "source": [
        "def proquery(query):\n",
        "  queryFinal=[]\n",
        "  query = cleaning(query,\" \",0)\n",
        "  queryFinal = gen_token(0,query)\n",
        "  queryFinal = remove_stopword(0,queryFinal)\n",
        "  queryFinal = normalise_using_textblob(0,queryFinal)\n",
        "  #queryFinal = queryFinal.replace(\",\",\" \").split()\n",
        "  return queryFinal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a0zcTf0pyVL"
      },
      "source": [
        "#preprocessing DocumentDict after Cleaning\n",
        "gen_token(1,\"\")\n",
        "remove_stopword(1,\"\")\n",
        "normalise_using_textblob(1,\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6j9OnLtqWtS",
        "outputId": "96f5e51b-e073-439b-e7c6-608b3f808f1e"
      },
      "source": [
        "len(documentsDict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "467"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiBLKckBsntD"
      },
      "source": [
        "documentsFilename = list(documentsDict.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pjbm6DbUZeLU"
      },
      "source": [
        "documentsFilename\n",
        "f = open(\"/content/drive/MyDrive/IR/documentsFilenameLemFinal.txt\",\"w\")\n",
        "f.write(str(documentsFilename))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taS5KfBXZ5bH"
      },
      "source": [
        "f = open(\"/content/drive/MyDrive/IR/documentsFilenameLemFinal.txt\",\"r\")\n",
        "x = f.read()\n",
        "x = x.replace(\"'\",\"\")\n",
        "x = x.replace(\"[\",\"\")\n",
        "x = x.replace(\"]\",\"\")\n",
        "documentsFilename = x.split(\",\")\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cjp_Lw_Iox7r"
      },
      "source": [
        "#Positional List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g__VCnpwx5d"
      },
      "source": [
        "Postings = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YOJOrUgBbJ8"
      },
      "source": [
        "Final Postings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMDuul8U_1dV"
      },
      "source": [
        "for docid in range(0,len(documentsFilename)):\n",
        "  tokensOfDocid = documentsDict[documentsFilename[docid]]\n",
        "  for position in range(0,len(tokensOfDocid)):\n",
        "    word = tokensOfDocid[position]\n",
        "    if word in Postings:\n",
        "      if docid in Postings.loc[1][word]:\n",
        "        Postings.loc[1][word][docid].append(position)\n",
        "      else:\n",
        "        Postings.iloc[1][word][docid] = [position]\n",
        "        Postings.iloc[0][word] = Postings.iloc[0][word] + 1\n",
        "    else:\n",
        "      Postings.insert(value=[1,{docid:[position]}], loc=0, column=word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rJom72Y_Fbx"
      },
      "source": [
        "Postings.to_csv(\"/content/drive/MyDrive/IR/PostingsLemFinal.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6_UEZDiEMfs"
      },
      "source": [
        "#Support for searching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23G0RSCH0Fk"
      },
      "source": [
        "Postings = pd.read_csv(\"/content/drive/MyDrive/IR/PostingsLemFinal.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12pEQNBeH81V"
      },
      "source": [
        "Postings = Postings.drop([\"Unnamed: 0\"],axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "0Ehw1tG2IODI",
        "outputId": "8e0e69d0-0afa-4800-c300-f570cb719968"
      },
      "source": [
        "Postings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>suborner</th>\n",
              "      <th>reconcilement</th>\n",
              "      <th>depose</th>\n",
              "      <th>vigilant</th>\n",
              "      <th>idolatrous</th>\n",
              "      <th>inhumanity</th>\n",
              "      <th>distributive</th>\n",
              "      <th>unclique</th>\n",
              "      <th>recalcitrat</th>\n",
              "      <th>yerks</th>\n",
              "      <th>unacquaintedness</th>\n",
              "      <th>cortez</th>\n",
              "      <th>ferdinando</th>\n",
              "      <th>remarkers</th>\n",
              "      <th>detecters</th>\n",
              "      <th>reflecters</th>\n",
              "      <th>considerers</th>\n",
              "      <th>answerer</th>\n",
              "      <th>illwill</th>\n",
              "      <th>descanting</th>\n",
              "      <th>brobdingnagians</th>\n",
              "      <th>finget</th>\n",
              "      <th>improba</th>\n",
              "      <th>mendacemque</th>\n",
              "      <th>etiam</th>\n",
              "      <th>vanum</th>\n",
              "      <th>chparagraphfinxit</th>\n",
              "      <th>sinonem</th>\n",
              "      <th>fortuna</th>\n",
              "      <th>miserum</th>\n",
              "      <th>impudently</th>\n",
              "      <th>credulity</th>\n",
              "      <th>falsity</th>\n",
              "      <th>copulating</th>\n",
              "      <th>rotherhith</th>\n",
              "      <th>accoutred</th>\n",
              "      <th>inquisition</th>\n",
              "      <th>abhorring</th>\n",
              "      <th>mendez</th>\n",
              "      <th>lisbon</th>\n",
              "      <th>...</th>\n",
              "      <th>new</th>\n",
              "      <th>daves</th>\n",
              "      <th>floor</th>\n",
              "      <th>paneled</th>\n",
              "      <th>sitting</th>\n",
              "      <th>snow</th>\n",
              "      <th>outside</th>\n",
              "      <th>focused</th>\n",
              "      <th>eye</th>\n",
              "      <th>asked</th>\n",
              "      <th>left</th>\n",
              "      <th>anything</th>\n",
              "      <th>laying</th>\n",
              "      <th>can</th>\n",
              "      <th>bottle</th>\n",
              "      <th>array</th>\n",
              "      <th>hitting</th>\n",
              "      <th>shifting</th>\n",
              "      <th>leg</th>\n",
              "      <th>replied</th>\n",
              "      <th>yeah</th>\n",
              "      <th>anyway</th>\n",
              "      <th>called</th>\n",
              "      <th>really</th>\n",
              "      <th>ahead</th>\n",
              "      <th>go</th>\n",
              "      <th>mind</th>\n",
              "      <th>look</th>\n",
              "      <th>said</th>\n",
              "      <th>dave</th>\n",
              "      <th>cancer</th>\n",
              "      <th>dropped</th>\n",
              "      <th>jamie</th>\n",
              "      <th>waited</th>\n",
              "      <th>hand</th>\n",
              "      <th>extended</th>\n",
              "      <th>mark</th>\n",
              "      <th>cigarette</th>\n",
              "      <th>another</th>\n",
              "      <th>give</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>250</td>\n",
              "      <td>8</td>\n",
              "      <td>166</td>\n",
              "      <td>2</td>\n",
              "      <td>133</td>\n",
              "      <td>39</td>\n",
              "      <td>156</td>\n",
              "      <td>27</td>\n",
              "      <td>298</td>\n",
              "      <td>220</td>\n",
              "      <td>283</td>\n",
              "      <td>244</td>\n",
              "      <td>44</td>\n",
              "      <td>303</td>\n",
              "      <td>83</td>\n",
              "      <td>24</td>\n",
              "      <td>37</td>\n",
              "      <td>23</td>\n",
              "      <td>138</td>\n",
              "      <td>145</td>\n",
              "      <td>97</td>\n",
              "      <td>122</td>\n",
              "      <td>228</td>\n",
              "      <td>236</td>\n",
              "      <td>95</td>\n",
              "      <td>320</td>\n",
              "      <td>230</td>\n",
              "      <td>302</td>\n",
              "      <td>348</td>\n",
              "      <td>25</td>\n",
              "      <td>11</td>\n",
              "      <td>127</td>\n",
              "      <td>2</td>\n",
              "      <td>121</td>\n",
              "      <td>289</td>\n",
              "      <td>56</td>\n",
              "      <td>82</td>\n",
              "      <td>40</td>\n",
              "      <td>300</td>\n",
              "      <td>245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{466: [65626]}</td>\n",
              "      <td>{466: [65562]}</td>\n",
              "      <td>{466: [65154]}</td>\n",
              "      <td>{466: [65055]}</td>\n",
              "      <td>{466: [64947]}</td>\n",
              "      <td>{466: [64913]}</td>\n",
              "      <td>{466: [64772]}</td>\n",
              "      <td>{466: [64654]}</td>\n",
              "      <td>{466: [64653]}</td>\n",
              "      <td>{466: [64638]}</td>\n",
              "      <td>{466: [64591]}</td>\n",
              "      <td>{466: [64491]}</td>\n",
              "      <td>{466: [64490]}</td>\n",
              "      <td>{466: [64413]}</td>\n",
              "      <td>{466: [64412]}</td>\n",
              "      <td>{466: [64411]}</td>\n",
              "      <td>{466: [64409]}</td>\n",
              "      <td>{466: [64408]}</td>\n",
              "      <td>{466: [64306]}</td>\n",
              "      <td>{466: [64210]}</td>\n",
              "      <td>{466: [64192, 64526]}</td>\n",
              "      <td>{466: [63996]}</td>\n",
              "      <td>{466: [63995]}</td>\n",
              "      <td>{466: [63994]}</td>\n",
              "      <td>{466: [63993]}</td>\n",
              "      <td>{466: [63992]}</td>\n",
              "      <td>{466: [63991]}</td>\n",
              "      <td>{466: [63989]}</td>\n",
              "      <td>{466: [63988]}</td>\n",
              "      <td>{466: [63987]}</td>\n",
              "      <td>{466: [63900]}</td>\n",
              "      <td>{466: [63896]}</td>\n",
              "      <td>{466: [63837]}</td>\n",
              "      <td>{466: [63398]}</td>\n",
              "      <td>{466: [63297]}</td>\n",
              "      <td>{466: [62917]}</td>\n",
              "      <td>{466: [62880]}</td>\n",
              "      <td>{466: [62735]}</td>\n",
              "      <td>{466: [62043, 63372]}</td>\n",
              "      <td>{466: [61887, 62611, 62790, 63195]}</td>\n",
              "      <td>...</td>\n",
              "      <td>{0: [47], 1: [178, 201, 221, 447], 2: [719, 72...</td>\n",
              "      <td>{0: [46, 84, 132], 32: [64, 147, 317, 896], 14...</td>\n",
              "      <td>{0: [45], 1: [391], 2: [149, 589, 2970, 3564, ...</td>\n",
              "      <td>{0: [44], 32: [60]}</td>\n",
              "      <td>{0: [43, 69, 105, 492], 2: [660, 1057, 1081, 1...</td>\n",
              "      <td>{0: [42, 172, 195, 217, 555], 6: [8906, 8913, ...</td>\n",
              "      <td>{0: [41, 147, 628], 2: [198, 930, 3033], 4: [6...</td>\n",
              "      <td>{0: [40], 32: [55], 72: [330], 96: [1004, 3400...</td>\n",
              "      <td>{0: [39, 144], 2: [1000, 1297, 1551, 1757, 188...</td>\n",
              "      <td>{0: [36, 646, 816], 1: [165], 2: [280, 654, 24...</td>\n",
              "      <td>{0: [33, 203], 1: [190, 325], 2: [699, 1104, 1...</td>\n",
              "      <td>{0: [32, 271, 765], 2: [599, 674, 1910, 3133],...</td>\n",
              "      <td>{0: [31, 167], 17: [423], 32: [46], 64: [202],...</td>\n",
              "      <td>{0: [30, 297, 677], 2: [2819, 3953], 4: [735, ...</td>\n",
              "      <td>{0: [29, 34], 5: [956, 1680, 1699, 1715, 1764,...</td>\n",
              "      <td>{0: [28], 5: [1191], 18: [1342], 23: [1095], 4...</td>\n",
              "      <td>{0: [27], 6: [10256, 18703, 31068], 16: [529],...</td>\n",
              "      <td>{0: [26], 23: [1802], 31: [6211], 32: [41], 86...</td>\n",
              "      <td>{0: [25], 1: [387], 2: [2980, 2991], 3: [42, 7...</td>\n",
              "      <td>{0: [24], 1: [114], 6: [2737, 3580, 8551, 9744...</td>\n",
              "      <td>{0: [22, 220, 236, 370, 425, 647, 778], 2: [75...</td>\n",
              "      <td>{0: [21], 1: [497], 2: [534], 3: [297], 6: [19...</td>\n",
              "      <td>{0: [20], 1: [303, 602], 2: [617, 1452, 2275, ...</td>\n",
              "      <td>{0: [18, 819], 1: [15], 4: [1382], 5: [841, 10...</td>\n",
              "      <td>{0: [17], 2: [2953], 4: [1645, 1717], 6: [1214...</td>\n",
              "      <td>{0: [16, 358, 383, 758], 1: [198], 2: [1055, 2...</td>\n",
              "      <td>{0: [15], 2: [1987, 3429], 3: [414], 5: [2013,...</td>\n",
              "      <td>{0: [14, 698, 815], 2: [356, 438, 975, 1492, 2...</td>\n",
              "      <td>{0: [12, 38, 216, 222, 248, 307, 372, 417, 443...</td>\n",
              "      <td>{0: [11, 35, 66, 235, 276, 280, 318, 371, 442,...</td>\n",
              "      <td>{0: [10, 19], 31: [4518], 32: [24, 33], 66: [4...</td>\n",
              "      <td>{0: [8], 5: [5326], 6: [2291, 2997, 13739, 182...</td>\n",
              "      <td>{0: [7, 62, 116, 139, 215, 249, 299, 416, 484,...</td>\n",
              "      <td>{0: [6], 2: [812, 3224, 3317], 3: [240], 6: [1...</td>\n",
              "      <td>{0: [5], 2: [7, 66, 558, 656, 682, 958, 1170, ...</td>\n",
              "      <td>{0: [4], 6: [178, 4507, 9309, 10478, 18922, 34...</td>\n",
              "      <td>{0: [3, 13, 23, 37, 49, 142, 221, 284, 325, 34...</td>\n",
              "      <td>{0: [2, 9, 56, 798], 6: [5232, 32374, 32417, 3...</td>\n",
              "      <td>{0: [1], 2: [847, 996, 1513, 1706, 3192, 3627]...</td>\n",
              "      <td>{0: [0], 2: [2790], 4: [474, 803, 1443], 5: [2...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 50523 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         suborner  ...                                               give\n",
              "0               1  ...                                                245\n",
              "1  {466: [65626]}  ...  {0: [0], 2: [2790], 4: [474, 803, 1443], 5: [2...\n",
              "\n",
              "[2 rows x 50523 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkeOI8TWIpWW"
      },
      "source": [
        "for column in Postings.columns:\n",
        "  xa = ast.literal_eval(Postings.iloc[1][column])\n",
        "  Postings.iloc[1][column] = xa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmUwJGQwbTA6"
      },
      "source": [
        "f = open(\"/content/drive/MyDrive/IR/documentsFilenameLemFinal.txt\",\"r\")\n",
        "x = f.read()\n",
        "x = x.replace(\"'\",\"\")\n",
        "x = x.replace(\"[\",\"\")\n",
        "x = x.replace(\"]\",\"\")\n",
        "documentsFilename = x.split(\",\")\n",
        "f.close()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQvuh3bAsgOG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b20978a2-dec8-45a0-f7f3-ed0aeed17b04"
      },
      "source": [
        "query = \"GOOD DAYS\"\n",
        "#do preprocessing\n",
        "tokenquery = proquery(query) #['to', 'be', 'or', 'not']\n",
        "#get machlist at each bi-iteration\n",
        "tokenPostingFirst = {}\n",
        "tempPosting = {}\n",
        "for token in range(0,len(tokenquery)-1):\n",
        "  if tokenquery[token] in Postings:\n",
        "    if tokenPostingFirst == {}:\n",
        "      tokenPostingFirst = Postings[tokenquery[token]][1]\n",
        "\n",
        "    else:\n",
        "      tokenPostingFirst = tempPosting\n",
        "      tempPosting = {}\n",
        "    #for nexttoken in range(token,len(tokenquery)):\n",
        "    if tokenquery[token+1] in Postings: \n",
        "      tokenPostingsecond = Postings[tokenquery[token +1]][1]\n",
        "      #checking same doc or not from tokenpostingfirst and second\n",
        "      for doc_id in tokenPostingFirst:\n",
        "        if doc_id in tokenPostingsecond:\n",
        "          #now checking positions of tokenfirst in docid consequtive or not with tokensecond\n",
        "          iteration = tokenPostingFirst[doc_id]\n",
        "          # print(str(type(iteration))+\" docid \"+str(doc_id)+\" token \"+str(token))\n",
        "          # print(iteration)\n",
        "          for positionOftoken in iteration:\n",
        "            if positionOftoken+1 in tokenPostingsecond[doc_id]:\n",
        "              if doc_id in tempPosting:\n",
        "                tempPosting[doc_id].append(positionOftoken +1)\n",
        "              else:\n",
        "                tempPosting[doc_id] = []\n",
        "                tempPosting[doc_id].append(positionOftoken + 1)\n",
        "  else:\n",
        "    break\n",
        "print(\"Entered Query : \"+ str(tokenquery))\n",
        "print(\"Number of Documents Retrieved : \"+ str(len(tempPosting.keys())))\n",
        "print(\"Documents containing query are following : \")\n",
        "for docid in tempPosting.keys():\n",
        "  print(documentsFilename[docid])"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Entered Query : ['good', 'day']\n",
            "Number of Documents Retrieved : 21\n",
            "Documents containing query are following : \n",
            "13chil.txt\n",
            " bruce-p.txt\n",
            " aesop11.txt\n",
            " aesopa10.txt\n",
            " fantasy.txt\n",
            " history5.txt\n",
            " hound-b.txt\n",
            " horswolf.txt\n",
            " melissa.txt\n",
            " mazarin.txt\n",
            " sick-kid.txt\n",
            " startrek.txt\n",
            " srex.txt\n",
            " breaks2.asc\n",
            " outcast.dos\n",
            " brain.damage\n",
            " fic5\n",
            " forgotte\n",
            " superg1\n",
            " enchdup.hum\n",
            " fantasy.hum\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "keJpuwV3HT30"
      },
      "source": [
        "Term Frequency in Docs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "OdTGGH7SsLEI",
        "outputId": "a12e06d8-0e87-4200-bd44-854c05b26969"
      },
      "source": [
        "file2 = pd.read_csv(\"/content/drive/MyDrive/IR ASSIGNMENT 2/PostingsLemFinal.csv\")\n",
        "file2 = file2.drop(\"Unnamed: 0\",axis=1)\n",
        "for column in file2.columns:\n",
        "  xa = ast.literal_eval(file2.iloc[1][column])\n",
        "  file2.iloc[1][column] = xa\n",
        "for col in file2:\n",
        "  for doc in file2.iloc[1][col]:\n",
        "    file2.iloc[1][col][doc]=len(file2.iloc[1][col][doc])\n",
        "file2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bordeaux</th>\n",
              "      <th>mademarchj</th>\n",
              "      <th>unlockmarchto</th>\n",
              "      <th>intertwine</th>\n",
              "      <th>elvish</th>\n",
              "      <th>enchant</th>\n",
              "      <th>songmarcha</th>\n",
              "      <th>fleecy</th>\n",
              "      <th>rokraven</th>\n",
              "      <th>staeorra</th>\n",
              "      <th>marsupial</th>\n",
              "      <th>amex</th>\n",
              "      <th>gecko</th>\n",
              "      <th>tissuealice</th>\n",
              "      <th>conjointly</th>\n",
              "      <th>minaret</th>\n",
              "      <th>oriel</th>\n",
              "      <th>saracenic</th>\n",
              "      <th>upspringing</th>\n",
              "      <th>streamlet</th>\n",
              "      <th>intertangled</th>\n",
              "      <th>tuberose</th>\n",
              "      <th>poppy</th>\n",
              "      <th>bosky</th>\n",
              "      <th>laved</th>\n",
              "      <th>begirt</th>\n",
              "      <th>amphitheatre</th>\n",
              "      <th>musically</th>\n",
              "      <th>diverging</th>\n",
              "      <th>wreathe</th>\n",
              "      <th>effulgence</th>\n",
              "      <th>luxuriance</th>\n",
              "      <th>clematis</th>\n",
              "      <th>eglantine</th>\n",
              "      <th>honeysuckle</th>\n",
              "      <th>overspread</th>\n",
              "      <th>cleanness</th>\n",
              "      <th>luxuriantly</th>\n",
              "      <th>divinest</th>\n",
              "      <th>bidden</th>\n",
              "      <th>...</th>\n",
              "      <th>time</th>\n",
              "      <th>long</th>\n",
              "      <th>seen</th>\n",
              "      <th>well</th>\n",
              "      <th>face</th>\n",
              "      <th>frown</th>\n",
              "      <th>slight</th>\n",
              "      <th>replied</th>\n",
              "      <th>yard</th>\n",
              "      <th>across</th>\n",
              "      <th>walked</th>\n",
              "      <th>cried</th>\n",
              "      <th>morning</th>\n",
              "      <th>good</th>\n",
              "      <th>exclaimed</th>\n",
              "      <th>paw</th>\n",
              "      <th>eye</th>\n",
              "      <th>shading</th>\n",
              "      <th>end</th>\n",
              "      <th>walking</th>\n",
              "      <th>himself</th>\n",
              "      <th>said</th>\n",
              "      <th>road</th>\n",
              "      <th>coming</th>\n",
              "      <th>like</th>\n",
              "      <th>look</th>\n",
              "      <th>looking</th>\n",
              "      <th>carrot</th>\n",
              "      <th>big</th>\n",
              "      <th>great</th>\n",
              "      <th>eating</th>\n",
              "      <th>rocking</th>\n",
              "      <th>porch</th>\n",
              "      <th>front</th>\n",
              "      <th>sat</th>\n",
              "      <th>rabbit</th>\n",
              "      <th>mr</th>\n",
              "      <th>fox</th>\n",
              "      <th>sly</th>\n",
              "      <th>child</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>407</td>\n",
              "      <td>302</td>\n",
              "      <td>230</td>\n",
              "      <td>333</td>\n",
              "      <td>276</td>\n",
              "      <td>28</td>\n",
              "      <td>70</td>\n",
              "      <td>145</td>\n",
              "      <td>94</td>\n",
              "      <td>196</td>\n",
              "      <td>194</td>\n",
              "      <td>115</td>\n",
              "      <td>181</td>\n",
              "      <td>297</td>\n",
              "      <td>83</td>\n",
              "      <td>35</td>\n",
              "      <td>298</td>\n",
              "      <td>5</td>\n",
              "      <td>251</td>\n",
              "      <td>109</td>\n",
              "      <td>132</td>\n",
              "      <td>348</td>\n",
              "      <td>121</td>\n",
              "      <td>175</td>\n",
              "      <td>382</td>\n",
              "      <td>302</td>\n",
              "      <td>232</td>\n",
              "      <td>5</td>\n",
              "      <td>214</td>\n",
              "      <td>238</td>\n",
              "      <td>76</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>203</td>\n",
              "      <td>197</td>\n",
              "      <td>27</td>\n",
              "      <td>119</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{466: 1}</td>\n",
              "      <td>{465: 1}</td>\n",
              "      <td>{465: 1}</td>\n",
              "      <td>{465: 1}</td>\n",
              "      <td>{464: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>{463: 1}</td>\n",
              "      <td>...</td>\n",
              "      <td>{0: 4, 1: 16, 2: 11, 3: 6, 4: 7, 5: 3, 6: 5, 7...</td>\n",
              "      <td>{0: 4, 1: 20, 2: 11, 3: 5, 4: 2, 11: 4, 12: 3,...</td>\n",
              "      <td>{0: 1, 1: 6, 2: 7, 3: 4, 4: 1, 6: 1, 11: 1, 13...</td>\n",
              "      <td>{0: 3, 1: 14, 2: 38, 3: 39, 5: 2, 6: 5, 8: 1, ...</td>\n",
              "      <td>{0: 2, 1: 16, 2: 12, 3: 8, 5: 2, 6: 1, 8: 1, 1...</td>\n",
              "      <td>{0: 1, 1: 1, 6: 1, 20: 7, 37: 1, 49: 1, 58: 3,...</td>\n",
              "      <td>{0: 2, 3: 1, 14: 1, 15: 1, 19: 1, 20: 28, 23: ...</td>\n",
              "      <td>{0: 4, 4: 1, 6: 2, 8: 1, 9: 2, 10: 1, 11: 6, 1...</td>\n",
              "      <td>{0: 1, 2: 6, 3: 1, 4: 1, 14: 1, 20: 1, 22: 1, ...</td>\n",
              "      <td>{0: 4, 1: 1, 2: 1, 3: 1, 12: 1, 13: 1, 14: 3, ...</td>\n",
              "      <td>{0: 1, 1: 1, 2: 1, 3: 2, 13: 2, 14: 4, 15: 1, ...</td>\n",
              "      <td>{0: 5, 2: 5, 3: 2, 6: 1, 11: 2, 14: 4, 15: 3, ...</td>\n",
              "      <td>{0: 4, 1: 2, 2: 5, 3: 6, 5: 2, 6: 1, 8: 1, 13:...</td>\n",
              "      <td>{0: 6, 1: 16, 2: 11, 3: 13, 4: 1, 5: 2, 9: 1, ...</td>\n",
              "      <td>{0: 2, 6: 2, 8: 2, 11: 2, 17: 2, 18: 1, 19: 2,...</td>\n",
              "      <td>{0: 2, 1: 1, 16: 5, 21: 1, 23: 2, 31: 1, 38: 1...</td>\n",
              "      <td>{0: 3, 1: 29, 2: 6, 3: 4, 5: 1, 6: 3, 9: 2, 10...</td>\n",
              "      <td>{0: 1, 66: 1, 174: 1, 361: 1, 422: 1}</td>\n",
              "      <td>{0: 2, 1: 10, 2: 3, 3: 5, 5: 2, 8: 2, 11: 1, 1...</td>\n",
              "      <td>{0: 2, 13: 1, 14: 2, 18: 1, 20: 12, 21: 3, 34:...</td>\n",
              "      <td>{0: 2, 4: 1, 6: 3, 8: 1, 11: 1, 16: 1, 17: 1, ...</td>\n",
              "      <td>{0: 5, 1: 8, 2: 33, 3: 43, 4: 7, 6: 5, 8: 3, 9...</td>\n",
              "      <td>{0: 2, 1: 9, 2: 11, 5: 9, 12: 3, 13: 1, 14: 3,...</td>\n",
              "      <td>{0: 1, 1: 6, 2: 1, 3: 1, 14: 1, 18: 2, 20: 41,...</td>\n",
              "      <td>{0: 2, 1: 53, 2: 6, 3: 10, 4: 5, 5: 2, 6: 1, 8...</td>\n",
              "      <td>{0: 2, 1: 10, 2: 3, 3: 7, 4: 1, 5: 1, 8: 2, 14...</td>\n",
              "      <td>{0: 1, 1: 1, 2: 2, 3: 2, 12: 2, 14: 5, 15: 2, ...</td>\n",
              "      <td>{0: 1, 66: 1, 74: 1, 86: 3, 344: 2}</td>\n",
              "      <td>{0: 2, 1: 13, 2: 1, 3: 3, 4: 1, 5: 1, 6: 2, 8:...</td>\n",
              "      <td>{0: 2, 1: 6, 2: 7, 3: 5, 4: 1, 5: 3, 6: 2, 7: ...</td>\n",
              "      <td>{0: 1, 1: 1, 5: 1, 13: 1, 16: 1, 21: 3, 26: 1,...</td>\n",
              "      <td>{0: 1, 20: 5, 58: 1, 74: 2, 144: 3, 195: 2, 22...</td>\n",
              "      <td>{0: 3, 21: 2, 45: 1, 74: 3, 96: 2, 102: 1, 128...</td>\n",
              "      <td>{0: 1, 1: 2, 2: 5, 3: 1, 6: 1, 14: 4, 18: 1, 2...</td>\n",
              "      <td>{0: 2, 1: 5, 2: 5, 6: 1, 8: 1, 13: 1, 14: 5, 1...</td>\n",
              "      <td>{0: 33, 5: 1, 18: 1, 54: 1, 58: 1, 60: 1, 65: ...</td>\n",
              "      <td>{0: 27, 2: 39, 3: 32, 10: 2, 14: 56, 15: 37, 1...</td>\n",
              "      <td>{0: 30, 28: 1, 37: 2, 45: 122, 48: 67, 60: 1, ...</td>\n",
              "      <td>{0: 26, 15: 1, 27: 1, 37: 1, 38: 2, 45: 1, 48:...</td>\n",
              "      <td>{0: 1, 1: 9, 5: 1, 6: 3, 11: 2, 14: 4, 16: 3, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 47672 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   bordeaux  ...                                              child\n",
              "0         1  ...                                                153\n",
              "1  {466: 1}  ...  {0: 1, 1: 9, 5: 1, 6: 3, 11: 2, 14: 4, 16: 3, ...\n",
              "\n",
              "[2 rows x 47672 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ub1Ubhuts5Ga"
      },
      "source": [
        "file2.to_csv(\"/content/drive/MyDrive/IR/FrequencyOfWord2.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}